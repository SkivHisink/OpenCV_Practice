{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "offshore-basin",
   "metadata": {},
   "source": [
    "# Seminar 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "continued-final",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "unsigned-limit",
   "metadata": {},
   "outputs": [],
   "source": [
    "img =cv.imread(\"photomode_01012021_191221.png\")\n",
    "img =cv.resize(img, (400,400))\n",
    "img2 =cv.imread(\"photomode_01012021_191221.png\", 0)\n",
    "img2 =cv.resize(img2, (400,400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "psychological-assault",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"Pic\", img)\n",
    "cv.imshow(\"Pict\", img2)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "sunrise-actor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "138931\n",
      "480000\n",
      "0.2894395833333333\n"
     ]
    }
   ],
   "source": [
    "x =int(input())\n",
    "counter = 0\n",
    "counter2 = 0\n",
    "for i in img.reshape(-1):\n",
    "    counter2+=1\n",
    "    if i < x:\n",
    "        counter+=1\n",
    "print(counter)\n",
    "print(counter2)\n",
    "print(counter/counter2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "rising-builder",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"cat.png\")\n",
    "img =cv.resize(img, (400,400))\n",
    "img2 = cv.imread(\"cat.png\")\n",
    "img2 =cv.resize(img2, (400,400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "national-research",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left eye\n",
    "start_point = (110, 200)\n",
    "end_point = (170, 250)\n",
    "color=(255, 0, 0)\n",
    "thickness = 2\n",
    "img2 = cv.rectangle(img2, start_point, end_point, color, thickness)\n",
    "# right eye\n",
    "start_point = (230, 200)\n",
    "end_point = (290, 250)\n",
    "color=(255, 0, 0)\n",
    "thickness = 2\n",
    "img2 = cv.rectangle(img2, start_point, end_point, color, thickness)\n",
    "# nose\n",
    "center_coordinates = (200, 300)\n",
    "radius = 28\n",
    "color=(0, 255, 0)\n",
    "img2 = cv.circle(img2, center_coordinates, radius, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "everyday-plate",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left ear\n",
    "# Polygon corner points coordinates\n",
    "pts = np.array([[25, 70], [40, 160], \n",
    "                [115, 80], [50, 30], \n",
    "                ],\n",
    "               np.int32)\n",
    "  \n",
    "pts = pts.reshape((-1, 1, 2))\n",
    "  \n",
    "isClosed = True\n",
    "  \n",
    "# Blue color in BGR\n",
    "color = (0, 0, 255)\n",
    "  \n",
    "# Line thickness of 2 px\n",
    "thickness = 2\n",
    "  \n",
    "# Using cv2.polylines() method\n",
    "# Draw a Blue polygon with \n",
    "# thickness of 1 px\n",
    "img2 = cv.polylines(img2, [pts], \n",
    "                      isClosed, color, thickness)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "forty-nightlife",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ellipse one\n",
    "radius = 100\n",
    "center = (370, 90)\n",
    "axes = (radius, radius)\n",
    "angle = 0\n",
    "startAngle = 100\n",
    "endAngle = 180\n",
    "img2 = cv.ellipse(img2, center, axes, angle, startAngle, endAngle, (100, 0, 100), 2)\n",
    "# Ellipse two\n",
    "radius = 95\n",
    "center = (365, 115)\n",
    "axes = (radius, radius)\n",
    "angle = 90\n",
    "startAngle = 100\n",
    "endAngle = 180\n",
    "img2 = cv.ellipse(img2, center, axes, angle, startAngle, endAngle, (100, 0, 100), 2)\n",
    "# Ellipse two\n",
    "radius = 50\n",
    "center = (330, 70)\n",
    "axes = (radius, radius)\n",
    "angle = 180\n",
    "startAngle = 100\n",
    "endAngle = 180\n",
    "img2 = cv.ellipse(img2, center, axes, angle, startAngle, endAngle, (100, 0, 100), 2)\n",
    "# Ellipse two\n",
    "radius = 50\n",
    "center = (330, 40)\n",
    "axes = (3*radius, radius)\n",
    "angle = 270\n",
    "startAngle = 100\n",
    "endAngle = 168\n",
    "img2 = cv.ellipse(img2, center, axes, angle, startAngle, endAngle, (100, 0, 100), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "promotional-mother",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"Pic\", img2)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "baking-syndication",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.imwrite(\"file.jpg\", img)\n",
    "cv.imwrite(\"file2.jpg\", img2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-facial",
   "metadata": {},
   "source": [
    "# Seminar 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "discrete-proposition",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "italian-junction",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "average-clinton",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"Task3.PNG\")\n",
    "img2 = cv.imread(\"Task3.PNG\", 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "absolute-begin",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"Pic\", img)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "handmade-friendship",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"Pic2\", img2)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "injured-season",
   "metadata": {},
   "outputs": [],
   "source": [
    "img2 =cv.adaptiveThreshold(img2, 255, cv.ADAPTIVE_THRESH_GAUSSIAN_C, cv.THRESH_BINARY, 27, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "distributed-wound",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"Pic\", img)\n",
    "cv.imshow(\"Pic2\", img2)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-editor",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "painted-netscape",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "def adjust_gamma(image, gamma=1.0):\n",
    "\t# build a lookup table mapping the pixel values [0, 255] to\n",
    "\t# their adjusted gamma values\n",
    "\tinvGamma = 1.0 / gamma\n",
    "\ttable = np.array([((i / 255.0) ** invGamma) * 255\n",
    "\t\tfor i in np.arange(0, 256)]).astype(\"uint8\")\n",
    "\t# apply gamma correction using the lookup table\n",
    "\treturn cv.LUT(image, table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "facial-rating",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"Task5.png\")\n",
    "gamma = 0\n",
    "alpha = int(0)\n",
    "beta = int(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "elegant-console",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHist(img, dst):\n",
    "    hist, bins = np.histogram(img.ravel(), 256, [0, 256])\n",
    "    hist = hist / hist.max() * 200\n",
    "    stack = np.vstack((np.linspace(0, 256, 256), hist.reshape(-1))).T\n",
    "    stack[:, 1] = dst.shape[0] - stack[:, 1]\n",
    "    cv.polylines(dst, [np.int32(stack)], True, (0, 255, 255))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "olympic-reliance",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gamma_alpha_beta():\n",
    "    img2 = img\n",
    "    #img2 = adjust_gamma(img, gamma)\n",
    "    #img2 = cv.convertScaleAbs(img2, alpha = alpha, beta = beta)\n",
    "    histogram = np.zeros((200, 256, 3), np.uint8)\n",
    "    imgGray = cv.cvtColor(img2, cv.COLOR_BGR2GRAY)\n",
    "    plotHist(imgGray, histogram)\n",
    "    imgGray = cv.equalizeHist(imgGray)\n",
    "    histogram_eq = np.zeros((200, 256, 3), np.uint8)\n",
    "    plotHist(imgGray, histogram_eq)\n",
    "    cv.imshow(\"Pic\", img2)\n",
    "    cv.imshow(\"equalized\", imgGray)\n",
    "    cv.imshow(\"Hist\", histogram)\n",
    "    cv.imshow(\"equalizedHist\", histogram_eq)\n",
    "def gammaf(val):\n",
    "    global gamma \n",
    "    gamma = val/128\n",
    "    gamma_alpha_beta()\n",
    "    \n",
    "def alphaf(val):\n",
    "    global alpha \n",
    "    alpha= val\n",
    "    gamma_alpha_beta()\n",
    "    \n",
    "def betaf(val):\n",
    "    global beta \n",
    "    beta = val\n",
    "    gamma_alpha_beta()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "capital-classics",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"Pic\", img)\n",
    "cv.createTrackbar('gamma', \"Pic\", 0, 255, gammaf)\n",
    "cv.createTrackbar('alpha', \"Pic\", 0, 255, alphaf)\n",
    "cv.createTrackbar('beta', \"Pic\", 0, 255, betaf)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "outstanding-knife",
   "metadata": {},
   "source": [
    "## Task5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "fresh-banana",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import random\n",
    "img = cv.imread(\"Task5.png\")\n",
    "img2 = cv.imread(\"Task5.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "informed-quarter",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = 15#int(float(input()))\n",
    "pic_number = 10\n",
    "img = np.float64(img)\n",
    "noise_pic = np.copy(img)\n",
    "a = list()\n",
    "for k in range(pic_number):\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            noise_val = random.randint(-noise, noise)\n",
    "            noise_pic[i][j] = img[i][j] + noise_val\n",
    "    a.append(np.copy(noise_pic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = np.asarray([np.add.reduce(i) for i in zip(*a)])\n",
    "result = (result/(pic_number)).astype('uint8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "boolean-findings",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"Pic\", result)\n",
    "cv.imshow(\"Pic2\", img2)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(pic_number):\n",
    "    cv.imshow(\"Pic\" + str(i), np.uint8(a[i]))\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[55 55 55]\n",
      "[54 54 54]\n",
      "[46 46 46]\n",
      "[51 51 51]\n",
      "[48 48 48]\n",
      "[47 47 47]\n",
      "[39 39 39]\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(a[i][50][50])\n",
    "print(result[50][50])\n",
    "print(img[50][50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Инициализация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_lowThreshold = 100\n",
    "title_trackbar_1 = 'Min Threshold:'\n",
    "title_trackbar_2 = 'Max Threshold:'\n",
    "ratio = 3\n",
    "kernel_size = 3\n",
    "# colors\n",
    "red_color = (0, 0, 255)\n",
    "green_color = (0, 255, 0)\n",
    "orange_color = (0, 128, 255)\n",
    "purple_color = (157,0, 90)\n",
    "blue_color = (255, 0, 0)\n",
    "magenta_color = (255, 0, 255)\n",
    "# bar variable \n",
    "low_threshold = 100\n",
    "max_threshold = 100\n",
    "\n",
    "max_level_contour = 0\n",
    "treshold_filter_level = 0\n",
    "exercise = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"Task6-3.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_six_zero_clear():\n",
    "    return img.copy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 6-0\n",
    "### Реализовать функцию фильтра Кенни"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CannyFilter(img, low_threshold, max_threshold):\n",
    "    img_blur = cv.blur(img, (3,3))\n",
    "    detected_edges = cv.Canny(img_blur, low_threshold, max_threshold, kernel_size)\n",
    "    mask = detected_edges != 0\n",
    "    canny_result = img * (mask[:,:,None].astype(img.dtype))\n",
    "    return detected_edges, canny_result\n",
    "\n",
    "def task_six_zero_Canny(dst):\n",
    "    return dst.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 6-1\n",
    "### Написать программу, выделяющую границы объектов методом Кэнни\n",
    "Реализовать выделение контуров объектов по изображению границ,\n",
    "полученному методом Кэнни для произвольного изображения, а также их\n",
    "визуализацию поверх исходного изображения.\n",
    "\n",
    "• Детектор границ Кэнни (cv::Canny)\n",
    "\n",
    "• Обнаружение и отрисовка контуров (cv:: findContours, cv::drawContours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_six_one(img2, contours, hierarchy):\n",
    "    cv.drawContours(img2, contours, -1, (0,255,0), 3, cv.LINE_AA, hierarchy, 1)\n",
    "    for c in contours:\n",
    "        x, y, w, h = cv.boundingRect(c)\n",
    "        rect_color = green_color\n",
    "        cv.rectangle(img2, (x, y), (x + w, y + h), rect_color, 1)\n",
    "    return img2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 6.2\n",
    "### Написать программу, которая автоматически определяет для одного объекта, выделенного методом Кэнни размер объекта (маленький, средний, большой) относительно общего размера изображения\n",
    "Выставлены ограничения при которых если площадь больше 5% - окрас квадрата зелёный, иначе если больше 3%(от 3% до 5%) - окрас оранжевый, иначе (от 0% до 3%) - окрас красный."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task_six_two(img2, contours):\n",
    "    x_img = img.shape[0]\n",
    "    y_img = img.shape[1]\n",
    "    square_img_s = x_img * y_img \n",
    "    for c in contours:\n",
    "        x, y, w, h = cv.boundingRect(c)\n",
    "        rect_color = red_color\n",
    "        rect_size = w * h\n",
    "        if rect_size >= (square_img_s / 20.):\n",
    "            rect_color = green_color\n",
    "        elif rect_size >= (square_img_s / 30.):\n",
    "            rect_color = orange_color\n",
    "        else:\n",
    "            rect_color = red_color\n",
    "        cv.rectangle(img2, (x, y), (x + w, y + h), rect_color, 1)\n",
    "    return img2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 6.3 \n",
    "### Написать программу, которая автоматически определяет для одного объекта, выделенного методом Кэнни форму объекта (кравдрат, прямоугольник, треугольник, круг, овал)\n",
    "Написана функция, которая возвращает имя найденной фигуры. Каждая фигура обводится своим цветом:\n",
    "\n",
    "Квадрат - зелёным;\n",
    "\n",
    "Прямоугольник - оранжевым;\n",
    "\n",
    "Треугольник - красным;\n",
    "\n",
    "Круг - фиолетовым;\n",
    "\n",
    "Овал - синим;\n",
    "\n",
    "Пятиугольник - маджента;\n",
    "\n",
    "Шестиугольник - белым.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Return approximated contour\n",
    "def approximate_contour(contour):\n",
    "    epsilon  =  0.02 * cv.arcLength(contour, True)\n",
    "    approximate = cv.approxPolyDP(contour, epsilon, True)\n",
    "    return approximate\n",
    "\n",
    "#Return length of vector\n",
    "def vector_len(v):\n",
    "    v = np.reshape(v, -1)\n",
    "    return np.sqrt(v[0] ** 2 + v[1] ** 2)\n",
    "\n",
    "#Return difference between two vectors\n",
    "def diff(x, y):\n",
    "    x = x.ravel()\n",
    "    y = y.ravel()\n",
    "    return [x[0] - y[0], x[1] - y[1]]\n",
    "\n",
    "#Return the name of the shape\n",
    "def find_shape(contour):\n",
    "    approximate = approximate_contour(contour)\n",
    "    if len(approximate) == 3:\n",
    "        shape = \"triangle\"\n",
    "    elif len(approximate) == 4:\n",
    "        (x, y, w, h) = cv.boundingRect(approximate)\n",
    "        figure_area = cv.contourArea(approximate)\n",
    "        approximate_area = vector_len(diff(approximate[0], approximate[1])) ** 2\n",
    "        area = figure_area / approximate_area\n",
    "        #Give small window for error\n",
    "        shape = \"square\" if 0.9 <= area <= 1.2 else \"rectangle\"\n",
    "    elif len(approximate) == 5:\n",
    "        shape = \"pentagon\"\n",
    "    elif len(approximate) == 6:\n",
    "        shape = \"hexagon\"\n",
    "    else:\n",
    "        M = cv.moments(approximate)\n",
    "        cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "        cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        radius = vector_len(approximate[0] - (cX, cY))\n",
    "        approximate_area = np.pi * (radius ** 2)\n",
    "        figure_area = cv.contourArea(approximate)\n",
    "        area = approximate_area / figure_area\n",
    "        if 0.9 <= area <= 1.2:\n",
    "            shape = \"circle\"\n",
    "        else:\n",
    "            shape = \"ellipse\"\n",
    "    return shape\n",
    "\n",
    "def task_six_three(img2, contours):\n",
    "    for c in contours:\n",
    "        x, y, w, h = cv.boundingRect(c)\n",
    "        rect_name = find_shape(c)\n",
    "        rect_color = (0,0,0)\n",
    "        if rect_name == \"square\":\n",
    "            rect_color = green_color\n",
    "        elif rect_name == \"rectangle\":\n",
    "            rect_color = orange_color\n",
    "        elif rect_name == \"triangle\":\n",
    "            rect_color = red_color\n",
    "        elif rect_name == \"circle\":\n",
    "            rect_color = purple_color\n",
    "        elif rect_name == \"ellipse\":\n",
    "            rect_color = blue_color\n",
    "        elif rect_name == \"pentagon\":\n",
    "            rect_color = magenta_color\n",
    "        elif rect_name == \"hexagon\":\n",
    "            rect_color = (255, 255, 255)\n",
    "        cv.rectangle(img2, (x, y), (x + w, y + h), rect_color, 1)\n",
    "    return img2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cutting contours noise\n",
    "def filter_contours(contours, tresh):\n",
    "    filtered = []\n",
    "    for c in contours:\n",
    "        approx = approximate_contour(c)\n",
    "        if cv.contourArea(approx) > tresh:\n",
    "            filtered.append(c)\n",
    "    return filtered\n",
    "\n",
    "def update():\n",
    "    global img\n",
    "    global low_threshold \n",
    "    global max_threshold\n",
    "    global treshold_filter_level\n",
    "    detected_edges, dst = CannyFilter(img, low_threshold, max_threshold)\n",
    "    contours, hierarchy = cv.findContours(detected_edges, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_NONE)\n",
    "    img2 = dst.copy()\n",
    "    contours = filter_contours(contours, tresh = treshold_filter_level)\n",
    "    if exercise == 0:\n",
    "        img2 = task_six_zero_clear()\n",
    "    elif exercise == 1:\n",
    "        img2 = task_six_zero_Canny(dst)\n",
    "    elif exercise == 2:\n",
    "        img2 = task_six_one(img2, contours, hierarchy)\n",
    "    elif exercise == 3: \n",
    "        img2 = task_six_two(img2, contours)\n",
    "    elif exercise == 4:\n",
    "        img2 = task_six_three(img2, contours)\n",
    "    cv.imshow(\"Pic\", img2)\n",
    "\n",
    "def CannyThresholdMin(val):\n",
    "    global low_threshold \n",
    "    low_threshold = val\n",
    "    update()\n",
    "\n",
    "def CannyThresholdMax(val):\n",
    "    global max_threshold\n",
    "    max_threshold = val\n",
    "    update()\n",
    "\n",
    "def TresholdFilterLevel(val):\n",
    "    global treshold_filter_level\n",
    "    treshold_filter_level = val\n",
    "    update()\n",
    "\n",
    "def exercise_f(val):\n",
    "    global exercise\n",
    "    exercise = val\n",
    "    update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"Pic\", img)\n",
    "cv.createTrackbar(title_trackbar_1, \"Pic\" , 190, max_lowThreshold*8, CannyThresholdMin)\n",
    "cv.createTrackbar(title_trackbar_2, \"Pic\" , 230, max_lowThreshold*8, CannyThresholdMax)\n",
    "cv.createTrackbar(\"TresholdFilterLevel\", \"Pic\" , 45, max_lowThreshold*6, TresholdFilterLevel)\n",
    "cv.createTrackbar(\"Task type\", \"Pic\" , 1, 4, exercise_f)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread(\"Task5.png\")\n",
    "img = cv.cvtColor(img, cv.COLOR_BGR2GRAY)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 7\n",
    "### Продемонстрировать возможности линейной фильтрации изображений на основе: Гауссова фильтра, медианного, фильтра с произвольным ядром, оператора Собеля, фильтра Лапласа. Продемонстрировать удаление равномерного шума и Гауссова.\n",
    "• Гауссов(cv::blur) и медианный фильтр (cv::medianBlur).\n",
    "\n",
    "• Фильтрация произвольной маской (cv::filter2D).\n",
    "\n",
    "• Выделение границ объектов (cv::Sobel).\n",
    "\n",
    "• Фильтр Лапласа. Исследовать влияние входных параметров на\n",
    "результат фильтрации, провести сравнение с фильтром Собеля.\n",
    "\n",
    "• cv::randn – нормальное распределение, cv::randu – равномерное\n",
    "распределение."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test of filters with kernel = 3\n",
    "if False:\n",
    "    cv.imshow(\"Pic\", img)\n",
    "    cv.imshow(\"Gauss\", cv.blur(img.copy(), (3, 3)))\n",
    "    kernel_size = 3\n",
    "    kernel = np.ones((kernel_size, kernel_size), dtype = np.float32)\n",
    "    kernel /= (kernel_size * kernel_size)\n",
    "    cv.imshow(\"filter2D\", cv.filter2D(img.copy(), cv.CV_8U, kernel))\n",
    "    cv.imshow(\"Sobel\", cv.Sobel(cv.blur(img, (3, 3)), cv.CV_64F, 1, 1, ksize = 3))\n",
    "    cv.imshow(\"Laplacian\", cv.Laplacian(cv.blur(img, (3, 3)), cv.CV_64F, ksize = 3))\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_noise(img, noise_size, is_normal):\n",
    "    noise = np.zeros(img.shape)\n",
    "    if is_normal:\n",
    "        cv.randn(noise, 0,  noise_size)\n",
    "    else:\n",
    "        cv.randu(noise, -noise_size, noise_size)\n",
    "    return noise\n",
    "\n",
    "def make_noise_img(img, noise_size, is_normal):\n",
    "    return np.uint8(np.clip(cv.add(np.float64(img), \\\n",
    "        make_noise(img, noise_size, is_normal)), 0, 255)) # Translate img to float, add noise to img(too has float type), clip it to borders of uint8 and translate it to uint8 \n",
    "\n",
    "def make_filtered_img(noise_img, filter_name, kernel_elem):\n",
    "    if filter_name == \"Origin\":\n",
    "        return img\n",
    "    elif filter_name == \"Gaussian\":\n",
    "        return cv.blur(noise_img, (kernel_elem, kernel_elem))\n",
    "    elif filter_name == \"Median\":\n",
    "        if kernel_elem % 2 != 1:\n",
    "            kernel_elem += 1\n",
    "        return cv.medianBlur(noise_img, kernel_elem) # Work only with kernel elem % 2 == 1\n",
    "    elif filter_name == \"Filter2D\":\n",
    "        return cv.filter2D(noise_img, cv.CV_8U, \\\n",
    "        np.ones((kernel_elem, kernel_elem), dtype = np.float64) / (kernel_elem * kernel_elem)) # Generating kernel that has sizes kernel_elem X kernel_elem and each element of this kernel is equal to 1.0 / kernel_elem\n",
    "    elif filter_name == \"Sobel\":\n",
    "        if kernel_elem % 2 != 1:\n",
    "            kernel_elem += 1\n",
    "        return cv.Sobel(cv.blur(noise_img, (kernel_elem, kernel_elem)), cv.CV_64F, 1, 1, ksize = kernel_elem) # Work only with kernel elem % 2 == 1\n",
    "    elif filter_name == \"Laplacian\":\n",
    "        if kernel_elem % 2 != 1:\n",
    "            kernel_elem += 1\n",
    "        return cv.Laplacian(cv.blur(img, (kernel_elem, kernel_elem)), cv.CV_64F, ksize=kernel_elem) # Work only with kernel elem % 2 == 1\n",
    "    else:\n",
    "        return None\n",
    "def plotHist(img, hist_size = (200, 256, 3)):\n",
    "    histogram = np.zeros(hist_size, np.uint8)\n",
    "    hist, bins = np.histogram(img.ravel(), 256, [0, 256])\n",
    "    hist = hist / hist.max() * 200\n",
    "    stack = np.vstack((np.linspace(0, 256, 256), hist.reshape(-1))).T\n",
    "    stack[:, 1] = histogram.shape[0] - stack[:, 1]\n",
    "    cv.polylines(histogram, [np.int32(stack)], True, (0, 255, 255))\n",
    "    return histogram\n",
    "def concat_img_hist():\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For trackbars\n",
    "is_normal = True\n",
    "noise_size = 40\n",
    "kernel_size = 3\n",
    "filter_names = list((\"Origin\", \"Gaussian\", \"Median\", \"Filter2D\", \"Sobel\", \"Laplacian\"))\n",
    "filter_type = 0\n",
    "# Images\n",
    "noise_img = make_noise_img(img, 40, True)\n",
    "filtered_img = make_filtered_img(noise_img, filter_names[filter_type], kernel_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update():\n",
    "    global filtered_img\n",
    "    global histogram\n",
    "    filtered_img = make_filtered_img(noise_img, filter_names[filter_type], kernel_size)\n",
    "    cv.imshow(\"Histogram\", plotHist(filtered_img))\n",
    "    cv.imshow(\"Filtered Pic\", filtered_img)\n",
    "    cv.imshow(\"Noise Pic\", noise_img)\n",
    "\n",
    "\n",
    "def change_noise(val):\n",
    "    global noise_img\n",
    "    global noise_size\n",
    "    noise_size = val\n",
    "    noise_img = make_noise_img(img, noise_size, is_normal)\n",
    "    update()\n",
    "\n",
    "\n",
    "def change_is_normal(val):\n",
    "    global noise_img\n",
    "    if val == 1:\n",
    "        is_normal = True\n",
    "    else:\n",
    "        is_normal = False\n",
    "    noise_img = make_noise_img(img, noise_size, is_normal)\n",
    "    update()\n",
    "\n",
    "\n",
    "def change_kernel_size(val):\n",
    "    global kernel_size\n",
    "    global filtered_img\n",
    "    if val > 0:\n",
    "        kernel_size = val\n",
    "        update()\n",
    "\n",
    "\n",
    "def change_filter_type(val):\n",
    "    global filtered_img\n",
    "    global filter_type\n",
    "    filter_type = val\n",
    "    update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Original or filtered image\n",
    "cv.imshow(\"Filtered Pic\", img)\n",
    "cv.createTrackbar(\"Type of Filter\",\"Filtered Pic\", 0, 5, change_filter_type)\n",
    "cv.createTrackbar(\"Filters kernel size\", \"Filtered Pic\", 3, 30, change_kernel_size)\n",
    "#Hist of image\n",
    "cv.imshow(\"Histogram\", plotHist(filtered_img))\n",
    "#Noise image\n",
    "cv.imshow(\"Noise Pic\", noise_img)\n",
    "cv.createTrackbar(\"noise size\", \"Noise Pic\", 40, 800, change_noise)\n",
    "cv.createTrackbar(\"normal/uniform\", \"Noise Pic\", 1, 1, change_is_normal)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задание 8\n",
    "### Реализовать поиск линий либо окружностей (на выбор) на характерных изображениях, исследовать эффективность при различных параметрах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Task-8.jpg')\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "rho_size = 1.0\n",
    "theta_devide_size = 360\n",
    "hough_treshold = 200\n",
    "low_threshold = 50\n",
    "high_threshold = 150\n",
    "aperture_size = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update():\n",
    "    edges = cv.Canny(gray, low_threshold, high_threshold, \\\n",
    "        apertureSize = aperture_size) # work only with 3 or 5\n",
    "    lines = cv.HoughLinesP(edges, rho_size, np.pi / theta_devide_size, hough_treshold, \\\n",
    "        minLineLength = 10, maxLineGap = 10)\n",
    "    #lines = cv.HoughLines(edges, rho_size, np.pi / theta_devide_size, hough_treshold)\n",
    "    res = img.copy()\n",
    "    for line in lines:\n",
    "        #rho,theta = line[0]\n",
    "        #a = np.cos(theta)\n",
    "        #b = np.sin(theta)\n",
    "        #x0 = a * rho\n",
    "        #y0 = b * rho\n",
    "        ## x1 stores the rounded off value of (r * cos(theta) - 1000 * sin(theta))\n",
    "        #x1 = int(x0 + 1000 * (-b))\n",
    "        ## y1 stores the rounded off value of (r * sin(theta)+ 1000 * cos(theta))\n",
    "        #y1 = int(y0 + 1000 * (a))\n",
    "        ## x2 stores the rounded off value of (r * cos(theta)+ 1000 * sin(theta))\n",
    "        #x2 = int(x0 - 1000 * (-b))\n",
    "        ## y2 stores the rounded off value of (r * sin(theta)- 1000 * cos(theta))\n",
    "        #y2 = int(y0 - 1000 * (a))\n",
    "        x1, y1, x2, y2 = line[0]\n",
    "        cv.line(res, (x1, y1), (x2, y2), (0, 0, 255), 2)\n",
    "    cv.imshow('image', res)\n",
    "\n",
    "def change_rho_size(val):\n",
    "    global rho_size\n",
    "    if val > 0:\n",
    "        rho_size = val / 100\n",
    "        update()\n",
    "\n",
    "\n",
    "def change_theta_size(val):\n",
    "    global theta_devide_size\n",
    "    if val > 0 :\n",
    "        theta_devide_size = val\n",
    "        update()\n",
    "\n",
    "\n",
    "def change_hough_treshold(val):\n",
    "    global hough_treshold\n",
    "    hough_treshold = val\n",
    "    update()\n",
    "\n",
    "\n",
    "def change_low_treshold(val):\n",
    "    global low_threshold\n",
    "    low_threshold = val\n",
    "    update()\n",
    "\n",
    "\n",
    "def change_high_threshold(val):\n",
    "    global high_threshold\n",
    "    high_threshold = val\n",
    "    update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow('image', img)\n",
    "cv.createTrackbar('rho', 'image', 100, 1000, change_rho_size)\n",
    "cv.createTrackbar('theta', 'image', 360, 360, change_theta_size)\n",
    "cv.createTrackbar('hough treshold', 'image', 100, 500, change_hough_treshold)\n",
    "cv.createTrackbar('low treshold', 'image', 50, 500, change_low_treshold)\n",
    "cv.createTrackbar('high threshold', 'image', 150, 500, change_high_threshold)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 9. \n",
    "### Использовать детектор углов Харриса и детектор особыхточек Ши-Томаси, исследовать влияние преобразований изображений (аффинные и перспективные преобразования, изменение яркости, контраста), а также параметров алгоритмов на результаты обнаружения локальных особенностей\n",
    "1.Harris corner detector\n",
    "(cv::cornerHarris);\n",
    "\n",
    "2.Shi-Tomachi\n",
    "(cv::goodFeaturesToTrack);\n",
    "\n",
    "3.Преобразования\n",
    "изображений\n",
    "(cv::warpAffine,\n",
    "cv::warpPerspective)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv.imread('Task-9.jpg')\n",
    "harris_img = img.copy()\n",
    "shi_tomachi_img = img.copy()\n",
    "rotated_img = img\n",
    "#\n",
    "bright_size = 10\n",
    "contrast_size = 10\n",
    "angle_size = 0.0\n",
    "scale_size = 1.0\n",
    "marker_list = list()\n",
    "marker_list.append(cv.MARKER_CROSS)\n",
    "marker_list.append(cv.MARKER_DIAMOND)\n",
    "marker_list.append(cv.MARKER_SQUARE)\n",
    "marker_list.append(cv.MARKER_STAR)\n",
    "marker_list.append(cv.MARKER_TILTED_CROSS)\n",
    "marker_list.append(cv.MARKER_TRIANGLE_DOWN)\n",
    "marker_list.append(cv.MARKER_TRIANGLE_UP)\n",
    "marker_type = 2\n",
    "marker_size = 2\n",
    "# For affine\n",
    "height, width = img.shape[:2]\n",
    "center = (width / 2, height / 2)\n",
    "# For perpective\n",
    "point_list=list()\n",
    "point_list.append((0, 0))\n",
    "point_list.append((img.shape[1], 0))\n",
    "point_list.append((img.shape[1], img.shape[0]))\n",
    "point_list.append((0, img.shape[0]))\n",
    "point_for_change = 0\n",
    "# For Harris \n",
    "block_size = 2\n",
    "k_size = 3\n",
    "k_p = 0.001\n",
    "show_gray_har = 0\n",
    "# For Shi_Tomachi\n",
    "corners_count = 80\n",
    "corners_quality = 0.05\n",
    "minimal_distance = 5\n",
    "show_gray_shi = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update():\n",
    "    global rotated_img\n",
    "    rotated_img = img.copy()\n",
    "    change_brightness(bright_size)\n",
    "    change_contrast(contrast_size)\n",
    "    rotate_matrix = cv.getRotationMatrix2D(center, angle_size, scale_size)\n",
    "    rotated_img = cv.warpAffine(rotated_img, rotate_matrix, (width, height))\n",
    "    matrix = cv.getPerspectiveTransform( np.float32([[0, 0], [img.shape[1], 0], [img.shape[1], img.shape[0]], [0, img.shape[0]]]), \\\n",
    "         np.float32(point_list))\n",
    "    rotated_img = cv.warpPerspective(rotated_img, matrix, (img.shape[1], img.shape[0]), cv.INTER_CUBIC, borderMode = cv.BORDER_CONSTANT, borderValue = (0, 0, 0))\n",
    "    cv.imshow('Pic', rotated_img)\n",
    "    update_Harris()\n",
    "    update_Shi_tomachi()\n",
    "\n",
    "\n",
    "def change_brightness( brightness):\n",
    "    global rotated_img\n",
    "    if brightness != 0:\n",
    "        rotated_img = cv.addWeighted(rotated_img, (255 - brightness) / 255, rotated_img, 0, brightness)\n",
    "\n",
    "\n",
    "\n",
    "def change_contrast( contrast):\n",
    "    global rotated_img\n",
    "    if contrast != 0:\n",
    "        f = 131 * (contrast + 127) / (127 * (131 - contrast))\n",
    "        rotated_img = cv.addWeighted(rotated_img, f, rotated_img, 0, 127 * (1 - f))\n",
    "\n",
    "\n",
    "def change_brightness_size(val):\n",
    "    global bright_size\n",
    "    bright_size = val\n",
    "    update()\n",
    "\n",
    "\n",
    "def change_contrast_size(val):\n",
    "    global contrast_size\n",
    "    contrast_size = val\n",
    "    update()\n",
    "\n",
    "\n",
    "def change_rotate_angle(val):\n",
    "    global angle_size\n",
    "    angle_size = val\n",
    "    update()\n",
    "\n",
    "\n",
    "def change_rotate_scale(val):\n",
    "    global scale_size\n",
    "    if val > 0:\n",
    "        scale_size = val / 10.0\n",
    "        update()\n",
    "\n",
    "\n",
    "def change_point_for_changing(val):\n",
    "    global point_for_change\n",
    "    point_for_change = val\n",
    "\n",
    "\n",
    "def change_point_x_val(val):\n",
    "    global point_list\n",
    "    _, old_y = point_list[point_for_change]\n",
    "    point_list[point_for_change] = (val, old_y)\n",
    "    update()   \n",
    "\n",
    "\n",
    "def change_point_y_val(val):\n",
    "    global point_list\n",
    "    old_x, _ = point_list[point_for_change]\n",
    "    point_list[point_for_change] = (old_x, val)\n",
    "    update() \n",
    "\n",
    "    \n",
    "def return_to_default(val):\n",
    "    global point_list\n",
    "    global scale_size\n",
    "    global angle_size\n",
    "    global contrast_size\n",
    "    global bright_size\n",
    "    scale_size = 1\n",
    "    angle_size = 0\n",
    "    point_list[0] = (0, 0)\n",
    "    point_list[1] = (img.shape[1], 0)\n",
    "    point_list[2] = (img.shape[1], img.shape[0])\n",
    "    point_list[3] = (0, img.shape[0])\n",
    "    update()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_Harris(gray = None):\n",
    "    gray = cv.cvtColor(rotated_img, cv.COLOR_BGR2GRAY)\n",
    "    corners = cv.cornerHarris(gray, block_size, k_size, k_p)\n",
    "    harris_img = rotated_img.copy()\n",
    "    if show_gray_har == 0:\n",
    "        harris_img[corners > 0.01 * corners.max()] = [0, 255, 0]\n",
    "        cv.imshow('Harris', harris_img)\n",
    "    else:\n",
    "        harris_img[corners > 0.01 * corners.max()] = [0, 0, 255]\n",
    "        cv.imshow('Harris', harris_img)\n",
    "\n",
    "def change_block_size(val):\n",
    "    global block_size\n",
    "    block_size = val\n",
    "    update_Harris()\n",
    "\n",
    "\n",
    "def change_k_size(val):\n",
    "    global k_size\n",
    "    if val % 2 == 0:\n",
    "        val += 1\n",
    "    k_size = val\n",
    "    update_Harris()\n",
    "\n",
    "\n",
    "def change_k_p(val):\n",
    "    global k_p\n",
    "    if val > 0:\n",
    "        k_p = val / 100\n",
    "        update_Harris()\n",
    "\n",
    "\n",
    "def change_res_col_h(val):\n",
    "    global show_gray_har\n",
    "    show_gray_har = val\n",
    "    update_Harris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_markers_shi(img_, corners, color =  (0, 255, 0)):\n",
    "    corners_int = np.int0(corners)\n",
    "    for corner in corners_int:\n",
    "        x, y = corner.ravel()\n",
    "        cv.drawMarker(img_, (x, y), color, marker_list[marker_type], marker_size)\n",
    "\n",
    "\n",
    "def update_Shi_tomachi():\n",
    "    gray = cv.cvtColor(rotated_img, cv.COLOR_BGR2GRAY)\n",
    "    corners = cv.goodFeaturesToTrack(gray, corners_count, corners_quality, minimal_distance, mask = cv.inRange(gray, 1, 255))\n",
    "    shi_tomachi_img = rotated_img.copy()\n",
    "    if show_gray_shi == 0:\n",
    "        draw_markers_shi(shi_tomachi_img, corners)\n",
    "        cv.imshow('Shi tomachi', shi_tomachi_img)\n",
    "    else:\n",
    "        draw_markers_shi(shi_tomachi_img, corners, (0, 0, 255))\n",
    "        cv.imshow('Shi tomachi', shi_tomachi_img)\n",
    "\n",
    "def change_corners_count(val):\n",
    "     global corners_count\n",
    "     if val > 0:\n",
    "         corners_count = val\n",
    "         update_Shi_tomachi()\n",
    "\n",
    "\n",
    "def change_corners_quality(val):\n",
    "    global corners_quality\n",
    "    if val > 0:\n",
    "        corners_quality = val / 100.0\n",
    "        update_Shi_tomachi()\n",
    "\n",
    "\n",
    "def change_minimal_distance(val):\n",
    "    global minimal_distance\n",
    "    minimal_distance = val\n",
    "    update_Shi_tomachi()\n",
    "\n",
    "def change_res_col_shi(val):\n",
    "    global show_gray_shi\n",
    "    show_gray_shi = val\n",
    "    update_Shi_tomachi()\n",
    "\n",
    "\n",
    "def change_marker_type(val):\n",
    "    global marker_type\n",
    "    marker_type = val\n",
    "    update_Shi_tomachi()\n",
    "\n",
    "\n",
    "def change_marker_size(val):\n",
    "    global marker_size\n",
    "    marker_size = val\n",
    "    update_Shi_tomachi()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do some things with begin pic\n",
    "cv.imshow('Pic', img)\n",
    "cv.namedWindow('Control')\n",
    "cv.createTrackbar('Brightness', 'Control', 0, 255, change_brightness_size)\n",
    "cv.createTrackbar('Contrast', 'Control', 0, 128, change_contrast_size)\n",
    "cv.createTrackbar('Angle', 'Control', 0, 360, change_rotate_angle)\n",
    "cv.createTrackbar('Scale', 'Control', 10, 360, change_rotate_scale)\n",
    "cv.createTrackbar('Point', 'Control', 0, 3, change_point_for_changing)\n",
    "cv.createTrackbar('X', 'Control', 0, img.shape[1] - 1, change_point_x_val)\n",
    "cv.createTrackbar('Y', 'Control', 0, img.shape[0] - 1, change_point_y_val)\n",
    "cv.namedWindow('Control2')\n",
    "cv.createTrackbar('Return', 'Control2', 0, 1, return_to_default)\n",
    "#Harris corners\n",
    "cv.imshow('Harris', harris_img)\n",
    "cv.createTrackbar('block size', 'Harris', 2, 50, change_block_size)\n",
    "cv.createTrackbar('kernel size', 'Harris', 3, 31, change_k_size)\n",
    "cv.createTrackbar('k', 'Harris', 10, 100, change_k_p)\n",
    "cv.createTrackbar('is gray', 'Harris', 0, 1, change_res_col_h)\n",
    "#Shi tomachi corners\n",
    "cv.imshow('Shi tomachi', shi_tomachi_img)\n",
    "cv.createTrackbar('corners count', 'Shi tomachi', 80, 300, change_corners_count)\n",
    "cv.createTrackbar('quality', 'Shi tomachi', 5, 100, change_corners_quality)\n",
    "cv.createTrackbar('min distance', 'Shi tomachi', 5, 100, change_minimal_distance)\n",
    "cv.createTrackbar('is gray', 'Shi tomachi', 0, 1, change_res_col_shi)\n",
    "cv.createTrackbar('Marker type', 'Shi tomachi', 0, len(marker_list) - 1, change_marker_type)\n",
    "cv.createTrackbar('Marker size', 'Shi tomachi', 2, 30, change_marker_size)\n",
    "\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import numpy as np\n",
    "import cv2 as cv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача 10. \n",
    "### Реализовать поиск соответствия особых точек на двух изображений (feature matching), исследовать работу в реальных условиях."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_FEATURES = 500\n",
    "GOOD_MATCH_PERCENT = 0.15\n",
    "\n",
    "def alignImages(im1, im2):\n",
    "\n",
    "  # Convert images to grayscale\n",
    "  im1Gray = cv.cvtColor(im1, cv.COLOR_BGR2GRAY)\n",
    "  im2Gray = cv.cvtColor(im2, cv.COLOR_BGR2GRAY)\n",
    "\n",
    "  # Detect ORB features and compute descriptors.\n",
    "  orb = cv.ORB_create(MAX_FEATURES)\n",
    "  keypoints1, descriptors1 = orb.detectAndCompute(im1Gray, None)\n",
    "  keypoints2, descriptors2 = orb.detectAndCompute(im2Gray, None)\n",
    "\n",
    "  # Match features.\n",
    "  matcher = cv.DescriptorMatcher_create(cv.DESCRIPTOR_MATCHER_BRUTEFORCE_HAMMING)\n",
    "  matches = matcher.match(descriptors1, descriptors2, None)\n",
    "\n",
    "  # Sort matches by score\n",
    "  matches.sort(key=lambda x: x.distance, reverse=False)\n",
    "\n",
    "  # Remove not so good matches\n",
    "  numGoodMatches = int(len(matches) * GOOD_MATCH_PERCENT)\n",
    "  matches = matches[:numGoodMatches]\n",
    "\n",
    "  # Draw top matches\n",
    "  imMatches = cv.drawMatches(im1, keypoints1, im2, keypoints2, matches, None)\n",
    "  cv.imshow(\"Matches\", imMatches)\n",
    "\n",
    "  # Extract location of good matches\n",
    "  points1 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "  points2 = np.zeros((len(matches), 2), dtype=np.float32)\n",
    "\n",
    "  for i, match in enumerate(matches):\n",
    "    points1[i, :] = keypoints1[match.queryIdx].pt\n",
    "    points2[i, :] = keypoints2[match.trainIdx].pt\n",
    "\n",
    "  # Find homography\n",
    "  h, mask = cv.findHomography(points1, points2, cv.RANSAC)\n",
    "\n",
    "  # Use homography\n",
    "  height, width, channels = im2.shape\n",
    "  im1Reg = cv.warpPerspective(im1, h, (width, height))\n",
    "\n",
    "  return im1Reg, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test 1\n",
    "# Read reference image\n",
    "imReference = cv.imread(\"form.jpg\", cv.IMREAD_COLOR)\n",
    "\n",
    "# Read image to be aligned\n",
    "im = cv.imread(\"scanned-form.jpg\", cv.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated homography : \n",
      " [[ 7.29442464e-01  9.87380448e-02  1.30465820e+01]\n",
      " [-9.45903137e-02  6.60757422e-01  6.59422430e+01]\n",
      " [ 1.88339775e-04 -1.86514430e-04  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Registered image will be resotred in imReg.\n",
    "# The estimated homography will be stored in h.\n",
    "imReg, h = alignImages(im, imReference)\n",
    "cv.imshow(\"Full image\", imReference)\n",
    "cv.imshow(\"Scanned image\", im)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "# Print estimated homography\n",
    "print(\"Estimated homography : \\n\",  h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test 2\n",
    "# Read reference image\n",
    "imReference = cv.imread(\"Colosseo4.jpg\", cv.IMREAD_COLOR)\n",
    "\n",
    "# Read image to be aligned\n",
    "im = cv.imread(\"Colosseo2.jpg\", cv.IMREAD_COLOR)\n",
    "imReference =cv.resize(imReference, (im.shape[1], im.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated homography : \n",
      " [[ 3.24956443e+00 -2.58492189e+00 -2.36415660e+02]\n",
      " [ 9.99912775e-01  1.93533459e-01 -1.94959419e+02]\n",
      " [ 2.08763439e-03 -3.09567099e-03  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Registered image will be resotred in imReg.\n",
    "# The estimated homography will be stored in h.\n",
    "imReg, h = alignImages(im, imReference)\n",
    "cv.imshow(\"Full image\", imReference)\n",
    "cv.imshow(\"Scanned image\", im)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "# Print estimated homography\n",
    "print(\"Estimated homography : \\n\",  h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test 3\n",
    "# Read reference image\n",
    "imReference = cv.imread(\"Lays1.png\", cv.IMREAD_COLOR)\n",
    "\n",
    "# Read image to be aligned\n",
    "im = cv.imread(\"Lays2.jpg\", cv.IMREAD_COLOR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated homography : \n",
      " [[ 6.50327264e-01  9.02902079e-02 -3.57634986e+01]\n",
      " [-5.43999893e-02  6.98701225e-01 -7.97120521e+01]\n",
      " [ 7.24375156e-05  1.92390043e-04  1.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "# Registered image will be resotred in imReg.\n",
    "# The estimated homography will be stored in h.\n",
    "imReg, h = alignImages(im, imReference)\n",
    "cv.imshow(\"Full image\", imReference)\n",
    "cv.imshow(\"Scanned image\", im)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()\n",
    "# Print estimated homography\n",
    "print(\"Estimated homography : \\n\",  h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2 as cv\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.ndimage import label\n",
    "\n",
    "\n",
    "img = cv.imread(\"segmentation.jpg\")\n",
    "img = cv.resize(img, (800, 800))\n",
    "gray = cv.cvtColor(img, cv.COLOR_BGR2GRAY)\n",
    "ret, img_morph = cv.threshold(gray, 0, 255, cv.THRESH_OTSU)\n",
    "img_morph = cv.morphologyEx(img_morph, cv.MORPH_OPEN, np.ones((3, 3), dtype=int))\n",
    "img_copy = img.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_threshold = 0\n",
    "high_threshold = 0\n",
    "iteration_num = 5\n",
    "ret, thresh = cv.threshold(gray, 20, 255, cv.THRESH_BINARY_INV + cv.THRESH_OTSU)\n",
    "\n",
    "def update():\n",
    "    global ret\n",
    "    global thresh\n",
    "    # delitating image\n",
    "    dilated_img = cv.dilate(img_morph, None, iterations = iteration_num)\n",
    "    dilated_img = dilated_img - cv.erode(dilated_img, None)\n",
    "    distances_transform = cv.distanceTransform(img_morph, cv.DIST_L2, 3)\n",
    "    # show distances_transform\n",
    "    cv.imshow('distances', distances_transform)\n",
    "    distances_transform = ((distances_transform - distances_transform.min()) / (distances_transform.max() - distances_transform.min()) * 255).astype(np.uint8)\n",
    "    ret, distances_transform = cv.threshold(distances_transform, low_threshold, high_threshold, cv.THRESH_BINARY)\n",
    "    # show thresh changing\n",
    "    cv.imshow(\"thresh\", distances_transform)\n",
    "    label_, num_features = label(distances_transform)\n",
    "    # Multiplying label array on 255 / (number of featuter + 1) to prevent deviding on zero\n",
    "    label_ = label_ * (255 / (num_features + 1))\n",
    "    # Completing the markers now.\n",
    "    label_[dilated_img == 255] = 255\n",
    "    # Using watershed\n",
    "    label_ = label_.astype(np.int32)\n",
    "    labels = cv.watershed(img, label_)\n",
    "    cv.imshow('labels', cv.convertScaleAbs(labels))\n",
    "    # Changing values that is equal -1\n",
    "    label_[label_ == -1] = 0\n",
    "    # Getting outlines as result\n",
    "    markers = 255 - label_.astype(np.uint8)\n",
    "    markers[markers != 255] = 0\n",
    "    markers = cv.dilate(markers, None)\n",
    "    #copy original image to add on it edges\n",
    "    result = img.copy()\n",
    "    result[markers == 255] = (0, 255, 0)\n",
    "    cv.imshow('Outlines', markers)\n",
    "    cv.imshow('Result', result)\n",
    "\n",
    "def change_low_treshold(val):\n",
    "    global low_threshold\n",
    "    low_threshold = val\n",
    "    update()\n",
    "\n",
    "def change_high_treshold(val):\n",
    "    global high_threshold\n",
    "    high_threshold = val\n",
    "    update()\n",
    "\n",
    "def change_iteration_num(val):\n",
    "    global iteration_num\n",
    "    iteration_num = val\n",
    "    update()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv.imshow(\"thresh\", thresh)\n",
    "cv.createTrackbar('thresh low', 'thresh', 20, 500, change_low_treshold)\n",
    "cv.createTrackbar('thresh high', 'thresh', 255, 500, change_high_treshold)\n",
    "cv.createTrackbar('iterations', 'thresh', 5, 100, change_iteration_num)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 12.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## First try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "from mtcnn import MTCNN\n",
    "from deepface import DeepFace\n",
    "from deepface.basemodels import VGGFace, OpenFace, Facenet, FbDeepFace\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "detector = MTCNN() # создание детектора"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_faces(img):\n",
    "    result = detector.detect_faces(img)  # обнаружение лиц на изображении\n",
    "    faces_list = list()\n",
    "    boundings = list()\n",
    "    for i in range(len(result)): \n",
    "        bounding_box = result[i]['box']  #  ограничивающие рамки\n",
    "        faces_list.append(img[bounding_box[1]: bounding_box[1] + bounding_box[3], bounding_box[0]:bounding_box[0] + bounding_box[2]])\n",
    "        boundings.append(result[i]['box'])\n",
    "        #cv.rectangle(image, (bounding_box[0], bounding_box[1]),\n",
    "        #(bounding_box[0]+bounding_box[2], bounding_box[1] + bounding_box[3]),(0,155,255), 2) #  ограничение области на изображении      \n",
    "    return faces_list, boundings\n",
    "def get_img_stats(img_path):\n",
    "    pred = DeepFace.analyze(img_path = img_path,  enforce_detection = False, actions = ['emotion', 'age', 'gender', 'race'])\n",
    "    return pred\n",
    "    #for key in pred['emotion']:\n",
    "    #    if pred['emotion'][key] > 10:\n",
    "    #        print(key, int(pred['emotion'][key]), \"%\") \n",
    "    #print(\"Age:\", pred['age'])\n",
    "    #print(\"Sex:\", pred['gender'])\n",
    "    #for key in pred['race']:\n",
    "    #    if pred['race'][key] > 10:\n",
    "    #        print(key, int(pred['race'][key]), \"%\")\n",
    "\n",
    "def save_faces(faces):\n",
    "    save_file_names = list()\n",
    "    for i in range(len(faces)):\n",
    "        save_file_names.append(\"face\"+str(i)+\".jpg\")\n",
    "        cv.imwrite(save_file_names[i], faces[i])\n",
    "    return save_file_names\n",
    "\n",
    "def delete_faces(face_pathes):\n",
    "    for i in range(len(face_pathes)):\n",
    "        os.remove(face_pathes[i])\n",
    "\n",
    "def show_age_and_gender(img_path):\n",
    "    img = cv.imread(img_path)\n",
    "    img2 = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n",
    "    faces, bound = detect_faces(img2)\n",
    "    save_pathes = save_faces(faces)\n",
    "    face_pred = list()\n",
    "    text_add_move = 30\n",
    "    for i in range(len(save_pathes)):\n",
    "        text_move = text_add_move\n",
    "        face_pred.append(get_img_stats(save_pathes[i]))\n",
    "        bounding_box = bound[i]\n",
    "        cv.rectangle(img, (bounding_box[0], bounding_box[1]),\n",
    "        (bounding_box[0] + bounding_box[2], bounding_box[1] + bounding_box[3]),(0,255,0), 2) #  ограничение области на изображении      \n",
    "        font = cv.FONT_HERSHEY_SIMPLEX\n",
    "        for key in face_pred[i]['emotion']:\n",
    "            if face_pred[i]['emotion'][key] > 10:\n",
    "                cv.putText(img, (key +\" \"+ str(int(face_pred[i]['emotion'][key]))+\"%\"), \n",
    "                (bounding_box[0] + 10, bounding_box[1] + text_move), \n",
    "                font, 1, (0, 0, 0), 2, cv.LINE_AA)\n",
    "                cv.putText(img, (key +\" \"+ str(int(face_pred[i]['emotion'][key]))+\"%\"), \n",
    "                (bounding_box[0] + 10, bounding_box[1] + text_move), \n",
    "                font, 1, (0, 255, 0), 1, cv.LINE_AA)\n",
    "                text_move += text_add_move\n",
    "        cv.putText(img, (\"Age:\" + str(face_pred[i]['age'])), \n",
    "                (bounding_box[0] + 10, bounding_box[1] + text_move), \n",
    "                font, 1, (0, 0, 0), 2, cv.LINE_AA)\n",
    "        cv.putText(img, (\"Age:\" + str(face_pred[i]['age'])), \n",
    "                (bounding_box[0] + 10, bounding_box[1] + text_move), \n",
    "                font, 1, (0, 255, 0), 1, cv.LINE_AA)\n",
    "        text_move+=text_add_move\n",
    "        cv.putText(img, (\"Sex:\" + str(face_pred[i]['gender'])), \n",
    "                (bounding_box[0] + 10, bounding_box[1] + text_move), \n",
    "                font, 1, (0, 0, 0), 2, cv.LINE_AA)\n",
    "        cv.putText(img, (\"Sex:\" + str(face_pred[i]['gender'])), \n",
    "                (bounding_box[0] + 10, bounding_box[1] + text_move), \n",
    "                font, 1, (0, 255, 0), 1, cv.LINE_AA)\n",
    "        text_move += text_add_move\n",
    "        for key in face_pred[i]['race']:\n",
    "            if face_pred[i]['race'][key] > 10:\n",
    "                cv.putText( img,  (str(key) + \" \" + str(int(face_pred[i]['race'][key]))+\"%\"), \n",
    "                (bounding_box[0] + 10, bounding_box[1] + text_move), \n",
    "                font, 1, (0, 0, 0), 2, cv.LINE_AA)\n",
    "                cv.putText( img,  (str(key) + \" \" + str(int(face_pred[i]['race'][key]))+\"%\"), \n",
    "                (bounding_box[0] + 10, bounding_box[1] + text_move), \n",
    "                font, 1, (0, 255, 0), 1, cv.LINE_AA)\n",
    "                text_move += text_add_move\n",
    "    delete_faces(save_pathes)\n",
    "    cv.imshow(\"Pic\", img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  7.93it/s]\n",
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  9.13it/s]\n",
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  9.71it/s]\n",
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  8.73it/s]\n",
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  9.64it/s]\n",
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  9.90it/s]\n",
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  9.98it/s]\n",
      "Action: race: 100%|██████████| 4/4 [00:00<00:00, 10.05it/s]\n",
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  8.01it/s]\n",
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  9.90it/s]\n",
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  9.83it/s]\n",
      "Action: race: 100%|██████████| 4/4 [00:00<00:00, 10.00it/s]\n",
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  9.79it/s]\n",
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  9.83it/s]\n",
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  9.83it/s]\n",
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  9.75it/s]\n",
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  9.89it/s]\n",
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  9.95it/s]\n",
      "Action: race: 100%|██████████| 4/4 [00:00<00:00, 10.07it/s]\n"
     ]
    }
   ],
   "source": [
    "pictures = ['task12.jpeg', 'task12.jpg', 'task12-1.jpg', 'task12-2.jpg', 'task12-3.jpg', 'task12-4.jpg', 'task12-5.jpg', 'task12-6.png']\n",
    "for i in pictures:   \n",
    "    show_age_and_gender(i)\n",
    "    cv.waitKey(0)\n",
    "    cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  9.64it/s]\n"
     ]
    }
   ],
   "source": [
    "show_age_and_gender()\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:00<00:00, 10.00it/s]\n",
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  9.95it/s]\n",
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  9.66it/s]\n",
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  9.80it/s]\n",
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  9.83it/s]\n"
     ]
    }
   ],
   "source": [
    "show_age_and_gender('task12-1.jpg')\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  7.95it/s]\n",
      "Action: race: 100%|██████████| 4/4 [00:00<00:00,  9.85it/s]\n"
     ]
    }
   ],
   "source": [
    "show_age_and_gender('task12-2.jpg')\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_age_and_gender('task12-3.jpg')\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fdb6fbf867c7187f7f8a8febc5c3788177bc371946a18d2edded7c37c02c74b2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
