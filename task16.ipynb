{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<VideoCapture 00000209E3B419F0>\n"
     ]
    }
   ],
   "source": [
    "captured_video = cv.VideoCapture('161.mp4')\n",
    "print(captured_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def concat_tile(im_list_2d):\n",
    "    return cv.vconcat([cv.hconcat(im_list_h) for im_list_h in im_list_2d])\n",
    "MOG = cv.createBackgroundSubtractorMOG2()\n",
    "KNN = cv.createBackgroundSubtractorKNN()\n",
    "\n",
    "_, frame_zero = captured_video.read()\n",
    "frame_zero = cv.resize(frame_zero, (640, 360))\n",
    "\n",
    "while True:\n",
    "    retval, frame = captured_video.read()\n",
    "    if not retval:\n",
    "        break\n",
    "    frame = cv.resize(frame, (640, 360))\n",
    "    MOGmask = MOG.apply(frame)\n",
    "    #MOGmask = cv.cvtColor(cv.merge([MOGmask,MOGmask,MOGmask]), cv.COLOR_RGB2BGR)\n",
    "    KNNmask = KNN.apply(frame)\n",
    "    res = cv.vconcat([MOGmask, MOGmask])\n",
    "    res_2 = cv.vconcat([cv.bitwise_and(frame, frame_zero, mask=MOGmask), cv.bitwise_and(frame, frame_zero, mask=KNNmask)])\n",
    "    cv.imshow('mog and knn ', res)\n",
    "    cv.imshow('bitwise_and mog and knn', res_2)\n",
    "    cv.imshow('frame',frame )\n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "captured_video.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<VideoCapture 00000209E3B41C70>\n"
     ]
    }
   ],
   "source": [
    "captured_video = cv.VideoCapture('161.mp4')\n",
    "print(captured_video)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 100,\n",
    "                       qualityLevel = 0.3,\n",
    "                       minDistance = 7,\n",
    "                       blockSize = 7 )\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),\n",
    "                  maxLevel = 2,\n",
    "                  criteria = (cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "# Create some random colors\n",
    "color = np.random.randint(0,255,(100,3))\n",
    "# Take first frame and find corners in it\n",
    "ret, old_frame = captured_video.read()\n",
    "old_frame = cv.resize(old_frame, (640, 360))\n",
    "old_gray = cv.cvtColor(old_frame, cv.COLOR_BGR2GRAY)\n",
    "p0 = cv.goodFeaturesToTrack(old_gray, mask = None, **feature_params)\n",
    "# Create a mask image for drawing purposes\n",
    "mask = np.zeros_like(old_frame)\n",
    "while(1):\n",
    "    ret,frame = captured_video.read()\n",
    "    frame = cv.resize(frame, (640, 360))\n",
    "    frame_gray = cv.cvtColor(frame, cv.COLOR_BGR2GRAY)\n",
    "    # calculate optical flow\n",
    "    p1, st, err = cv.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "    # Select good points\n",
    "    if p1 is not None:\n",
    "        good_new = p1[st==1]\n",
    "        good_old = p0[st==1]\n",
    "    # draw the tracks\n",
    "    for i,(new,old) in enumerate(zip(good_new, good_old)):\n",
    "        a,b = new.ravel()\n",
    "        c,d = old.ravel()\n",
    "        mask = cv.line(mask, (int(a),int(b)),(int(c),int(d)), color[i].tolist(), 2)\n",
    "        frame = cv.circle(frame,(int(a),int(b)),5,color[i].tolist(),-1)\n",
    "    img = cv.add(frame,mask)\n",
    "    cv.imshow('frame',img)\n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    # Now update the previous frame and previous points\n",
    "    old_gray = frame_gray.copy()\n",
    "    p0 = good_new.reshape(-1,1,2)\n",
    "\n",
    "captured_video.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import torchvision\n",
    "import torchvision.utils\n",
    "from torchvision.models import detection\n",
    "from torchvision.models.detection.faster_rcnn import FastRCNNPredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<VideoCapture 00000209E3B41570>\n"
     ]
    }
   ],
   "source": [
    "captured_video = cv.VideoCapture('163.mkv')\n",
    "print(captured_video)\n",
    "\n",
    "device = torch.device(\"cuda:0\")\n",
    "#device = torch.device(\"cpu\")\n",
    "\n",
    "model = torchvision.models.detection.fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()\n",
    "model = model.float().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5\n",
    "\n",
    "frame_idx = 0\n",
    "label = None\n",
    "\n",
    "while True:\n",
    "    retval, frame = captured_video.read()\n",
    "    if not retval:\n",
    "        break\n",
    "\n",
    "    frame = cv.resize(frame, (640, 360))\n",
    "\n",
    "    frame = torch.tensor(np.swapaxes(np.swapaxes(frame, 0, 2),1,2)).float() / 255\n",
    "\n",
    "    if (frame_idx % 20 == 0 and frame_idx >= 60): # 'and frame_idx >= 50' only for skipping start vieo in my situation\n",
    "        label = model([frame.to(device)])[0]\n",
    "\n",
    "    frame =  frame.permute(1, 2, 0).detach().cpu().numpy()\n",
    "\n",
    "    if (label!=None):\n",
    "        for i in range(len(label[\"labels\"])):\n",
    "            if label[\"scores\"][i] < threshold:\n",
    "                continue\n",
    "            if label[\"labels\"][i] == 1:\n",
    "                frame = cv.rectangle(frame, (int(label['boxes'][i][0]), int(label['boxes'][i][1]) ), ( int(label['boxes'][i][2]),int(label['boxes'][i][3])), (255,0,0), 1)\n",
    "\n",
    "    cv.imshow('frame', frame)\n",
    "\n",
    "    #print(frame_idx)\n",
    "    frame_idx +=1\n",
    "\n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "\n",
    "captured_video.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "captured_video.release()\n",
    "cv.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fdb6fbf867c7187f7f8a8febc5c3788177bc371946a18d2edded7c37c02c74b2"
  },
  "kernelspec": {
   "display_name": "Python 3.7.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
